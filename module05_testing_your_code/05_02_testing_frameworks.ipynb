{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use testing frameworks?\n",
    "\n",
    "Frameworks should simplify our lives:\n",
    "\n",
    "* Should be easy to add simple test\n",
    "* Should be possible to create complex test:\n",
    "    * Fixtures\n",
    "    * Setup/Tear down\n",
    "    * Parameterized tests (same test, mostly same input)\n",
    "* Find all our tests in a complicated code-base \n",
    "* Run all our tests with a quick command\n",
    "* Run only some tests, e.g. ``test --only \"tests about fields\"``\n",
    "* **Report failing tests**\n",
    "* Additional goodies, such as code coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common testing frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Language agnostic: [CTest](http://www.cmake.org/cmake/help/v2.8.12/ctest.html)\n",
    "  * Test runner for executables, bash scripts, etc...\n",
    "  * Great for legacy code hardening\n",
    "    \n",
    "* C unit-tests:\n",
    "    * all c++ frameworks,\n",
    "    * [Check](http://check.sourceforge.net/),\n",
    "    * [CUnit](http://cunit.sourceforge.net)\n",
    "\n",
    "* C++ unit-tests:\n",
    "    * [CppTest](http://cpptest.sourceforge.net/),\n",
    "    * [Boost::Test](http://www.boost.org/doc/libs/1_55_0/libs/test/doc/html/index.html),\n",
    "    * [google-test](https://code.google.com/p/googletest/),\n",
    "    * [Catch](https://github.com/philsquared/Catch) (best)\n",
    "\n",
    "* Python unit-tests:\n",
    "    * [nose](https://nose.readthedocs.org/en/latest/) includes test discovery, coverage, etc\n",
    "    * [unittest](http://docs.python.org/2/library/unittest.html) comes with standard python library\n",
    "    * [py.test](http://pytest.org/latest/), branched off of nose\n",
    "\n",
    "* R unit-tests:\n",
    "    * [RUnit](http://cran.r-project.org/web/packages/RUnit/index.html),\n",
    "    * [svUnit](http://cran.r-project.org/web/packages/svUnit/index.html)\n",
    "    * (works with [SciViews](http://www.sciviews.org/) GUI)\n",
    "\n",
    "* Fortran unit-tests:\n",
    "    * [funit](http://nasarb.rubyforge.org/funit/),\n",
    "    * [pfunit](http://sourceforge.net/projects/pfunit/)(works with MPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## py.test framework: usage\n",
    "\n",
    "[py.test](https://docs.pytest.org/en/latest/) is a recommended python testing framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use its tools in the notebook for on-the-fly tests in the notebook. This, happily, includes the negative-tests example we were looking for a moment ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def I_only_accept_positive_numbers(number):\n",
    "    # Check input\n",
    "    if number < 0:\n",
    "        raise ValueError(\"Input \" + str(number) + \" is negative\")\n",
    "\n",
    "    # Do something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytest import raises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with raises(ValueError):\n",
    "    I_only_accept_positive_numbers(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but the real power comes when we write a test file alongside our code files in our homemade packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#on windows replace '%%bash' with %%cmd\n",
    "rm -f saskatchewan\n",
    "mkdir -p saskatchewan\n",
    "# touch saskatchewan/__init__.py #on windows replace with 'type nul > saskatchewan/__init__.py'\n",
    "type nul > saskatchewan/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19042.1466]\r\n",
      "(c) Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(rse_course_2022) C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code>#on windows replace '%%bash' with %%cmd\n",
      "\r\n",
      "(rse_course_2022) C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code>rmdir /s saskatchewan\n",
      "saskatchewan, Are you sure (Y/N)? mkdir -p saskatchewan\n",
      "saskatchewan, Are you sure (Y/N)? ## touch saskatchewan/__init__.py #on windows replace with 'type nul > saskatchewan/__init__.py'\n",
      "saskatchewan, Are you sure (Y/N)? type nul > saskatchewan/__init__.py\n",
      "saskatchewan, Are you sure (Y/N)? dir\n",
      "saskatchewan, Are you sure (Y/N)? \r\n",
      "\r\n",
      "(rse_course_2022) C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'#on' is not recognized as an internal or external command,\r\n",
      "operable program or batch file.\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd   # or ! before every command\n",
    "#on windows replace '%%bash' with %%cmd\n",
    "rmdir /s saskatchewan\n",
    "mkdir -p saskatchewan\n",
    "## touch saskatchewan/__init__.py #on windows replace with 'type nul > saskatchewan/__init__.py'\n",
    "type nul > saskatchewan/__init__.py\n",
    "dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting saskatchewan/overlap.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile saskatchewan/overlap.py\n",
    "def overlap(field1, field2):\n",
    "    left1, bottom1, top1, right1 = field1\n",
    "    left2, bottom2, top2, right2 = field2\n",
    "\n",
    "    overlap_left = max(left1, left2)\n",
    "    overlap_bottom = max(bottom1, bottom2)\n",
    "    overlap_right = min(right1, right2)\n",
    "    overlap_top = min(top1, top2)\n",
    "    # Here's our wrong code again\n",
    "    overlap_height = overlap_top - overlap_bottom\n",
    "    overlap_width = overlap_right - overlap_left\n",
    "\n",
    "    return overlap_height * overlap_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing saskatchewan/test_overlap.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile saskatchewan/test_overlap.py\n",
    "from .overlap import overlap\n",
    "\n",
    "\n",
    "def test_full_overlap():\n",
    "    assert overlap((1.0, 1.0, 4.0, 4.0), (2.0, 2.0, 3.0, 3.0)) == 1.0\n",
    "\n",
    "\n",
    "def test_partial_overlap():\n",
    "    assert overlap((1, 1, 4, 4), (2, 2, 3, 4.5)) == 2.0\n",
    "\n",
    "\n",
    "def test_no_overlap():\n",
    "    assert overlap((1, 1, 4, 4), (4.5, 4.5, 5, 5)) == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.19042.1466]\r\n",
      "(c) Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(rse_course_2022) C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code>dir\n",
      " Volume in drive C is OS\r\n",
      " Volume Serial Number is 4CD9-CA7E\r\n",
      "\r\n",
      " Directory of C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code\r\n",
      "\r\n",
      "21/01/2022  15:03    <DIR>          .\r\n",
      "21/01/2022  15:03    <DIR>          ..\r\n",
      "21/01/2022  14:12    <DIR>          -p\r\n",
      "21/01/2022  14:27    <DIR>          .ipynb_checkpoints\r\n",
      "21/01/2022  14:13    <DIR>          .pytest_cache\r\n",
      "21/01/2022  13:13             4,671 05_00_introduction.ipynb\r\n",
      "21/01/2022  13:49            58,443 05_01_how_to_test.ipynb\r\n",
      "21/01/2022  15:03            24,074 05_02_testing_frameworks.ipynb\r\n",
      "21/01/2022  14:57            24,203 05_03_energy_example.ipynb\r\n",
      "17/01/2022  13:45            77,160 05_04_mocking.ipynb\r\n",
      "17/01/2022  13:45             7,075 05_05_using_a_debugger.ipynb\r\n",
      "17/01/2022  13:45             2,034 05_06_continuous_integration.ipynb\r\n",
      "17/01/2022  13:45         2,934,901 05_07_diffusion_example.ipynb\r\n",
      "17/01/2022  13:45               244 commands\r\n",
      "21/01/2022  14:13    <DIR>          diffusion\r\n",
      "17/01/2022  13:45    <DIR>          figures\r\n",
      "17/01/2022  13:45               135 index.md\r\n",
      "21/01/2022  14:19    <DIR>          saskatchewan\r\n",
      "17/01/2022  13:45    <DIR>          solutions\r\n",
      "              10 File(s)      3,132,940 bytes\r\n",
      "               9 Dir(s)  884,776,546,304 bytes free\r\n",
      "\r\n",
      "(rse_course_2022) C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code>!chdir saskatchewan\n",
      "\r\n",
      "(rse_course_2022) C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code>dir\n",
      " Volume in drive C is OS\r\n",
      " Volume Serial Number is 4CD9-CA7E\r\n",
      "\r\n",
      " Directory of C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code\r\n",
      "\r\n",
      "21/01/2022  15:03    <DIR>          .\r\n",
      "21/01/2022  15:03    <DIR>          ..\r\n",
      "21/01/2022  14:12    <DIR>          -p\r\n",
      "21/01/2022  14:27    <DIR>          .ipynb_checkpoints\r\n",
      "21/01/2022  14:13    <DIR>          .pytest_cache\r\n",
      "21/01/2022  13:13             4,671 05_00_introduction.ipynb\r\n",
      "21/01/2022  13:49            58,443 05_01_how_to_test.ipynb\r\n",
      "21/01/2022  15:03            24,074 05_02_testing_frameworks.ipynb\r\n",
      "21/01/2022  14:57            24,203 05_03_energy_example.ipynb\r\n",
      "17/01/2022  13:45            77,160 05_04_mocking.ipynb\r\n",
      "17/01/2022  13:45             7,075 05_05_using_a_debugger.ipynb\r\n",
      "17/01/2022  13:45             2,034 05_06_continuous_integration.ipynb\r\n",
      "17/01/2022  13:45         2,934,901 05_07_diffusion_example.ipynb\r\n",
      "17/01/2022  13:45               244 commands\r\n",
      "21/01/2022  14:13    <DIR>          diffusion\r\n",
      "17/01/2022  13:45    <DIR>          figures\r\n",
      "17/01/2022  13:45               135 index.md\r\n",
      "21/01/2022  14:19    <DIR>          saskatchewan\r\n",
      "17/01/2022  13:45    <DIR>          solutions\r\n",
      "              10 File(s)      3,132,940 bytes\r\n",
      "               9 Dir(s)  884,776,546,304 bytes free\r\n",
      "\r\n",
      "(rse_course_2022) C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code>py.test || echo \"Tests failed\"\n",
      "============================= test session starts =============================\r\n",
      "platform win32 -- Python 3.9.7, pytest-6.2.5, py-1.11.0, pluggy-1.0.0\r\n",
      "rootdir: C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code\r\n",
      "collected 14 items / 1 error / 13 selected\r\n",
      "\r\n",
      "=================================== ERRORS ====================================\r\n",
      "________ ERROR collecting solutions/diffusionmodel/test_derivatives.py ________\r\n",
      "ImportError while importing test module 'C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code\\solutions\\diffusionmodel\\test_derivatives.py'.\r\n",
      "Hint: make sure your test modules/packages have valid Python names.\r\n",
      "Traceback:\r\n",
      "..\\..\\..\\..\\..\\Anaconda3\\envs\\rse_course_2022\\lib\\importlib\\__init__.py:127: in import_module\r\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\r\n",
      "solutions\\diffusionmodel\\test_derivatives.py:2: in <module>\r\n",
      "    from mock import MagicMock\r\n",
      "E   ModuleNotFoundError: No module named 'mock'\r\n",
      "============================== warnings summary ===============================\r\n",
      "..\\..\\..\\..\\..\\Anaconda3\\envs\\rse_course_2022\\lib\\site-packages\\nose\\importer.py:12\r\n",
      "  C:\\Users\\dmassegur\\Anaconda3\\envs\\rse_course_2022\\lib\\site-packages\\nose\\importer.py:12: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\r\n",
      "    from imp import find_module, load_module, acquire_lock, release_lock\r\n",
      "\r\n",
      "-- Docs: https://docs.pytest.org/en/stable/warnings.html\r\n",
      "=========================== short test summary info ===========================\r\n",
      "ERROR solutions/diffusionmodel/test_derivatives.py\r\n",
      "!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\r\n",
      "========================= 1 warning, 1 error in 0.34s =========================\r\n",
      "\"Tests failed\"\r\n",
      "\r\n",
      "(rse_course_2022) C:\\Users\\dmassegur\\Projects\\P001 - RSE Course\\Materials\\rse-course\\module05_testing_your_code>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'!chdir' is not recognized as an internal or external command,\r\n",
      "operable program or batch file.\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd #(windows)    %%bash (linux)\n",
    "dir\n",
    "!chdir saskatchewan\n",
    "dir\n",
    "py.test || echo \"Tests failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it reported **which** test had failed, how many tests ran, and how many failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The symbol `..F` means there were three tests, of which the third one failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytest will:\n",
    "\n",
    "* automagically finds files ``test_*.py``\n",
    "* collects all subroutines called ``test_*``\n",
    "* runs tests and reports results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some options:\n",
    "\n",
    "* help: `py.test --help`\n",
    "* run only tests for a given feature: `py.test -k foo` # tests with 'foo' in the test name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with floating points\n",
    "\n",
    "## Floating points are not reals\n",
    "\n",
    "\n",
    "Floating points are inaccurate representations of real numbers:\n",
    "\n",
    "`1.0 == 0.99999999999999999` is true to the last bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can lead to numerical errors during calculations: $1000 (a - b) \\neq 1000a - 1000b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2737367544323206e-13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000.0 * 1.0 - 1000.0 * 0.9999999999999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000.0 * (1.0 - 0.9999999999999998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Both* results are wrong: `2e-13` is the correct answer.\n",
    "\n",
    "The size of the error will depend on the magnitude of the floating points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4901161193847656e-08"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000.0 * 1e5 - 1000.0 * 0.9999999999999998e5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result should be `2e-8`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing floating points\n",
    "\n",
    "Use the \"approx\", for a default of a relative tolerance of $10^{-6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "from pytest import approx\n",
    "\n",
    "assert 0.7 == approx(0.7 + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or be more explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "magnitude = 0.7\n",
    "assert 0.7 == approx(0.701, rel=0.1, abs=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing tolerances is a big area of debate: https://software-carpentry.org/blog/2014/10/why-we-dont-teach-testing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing vectors of floating points\n",
    "\n",
    "Numerical vectors are best represented using [numpy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array, pi\n",
    "\n",
    "vector_of_reals = array([0.1, 0.2, 0.3, 0.4]) * pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy ships with a number of assertions (in ``numpy.testing``) to make\n",
    "comparison easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-05, atol=1e-13\n\nMismatched elements: 1 / 5 (20%)\nMax absolute difference: 1.e-06\nMax relative difference: 1.\n x: array([3.141603e-01, 6.283195e-01, 9.424788e-01, 1.256638e+00,\n       6.283185e-12])\n y: array([3.141593e-01, 6.283185e-01, 9.424778e-01, 1.256637e+00,\n       3.141593e-12])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DMASSE~1\\AppData\\Local\\Temp/ipykernel_3388/899692519.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mactual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2e-12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mactual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0massert_allclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\rse_course_2022\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[1;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[0;32m    842\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[1;32m--> 844\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-05, atol=1e-13\n\nMismatched elements: 1 / 5 (20%)\nMax absolute difference: 1.e-06\nMax relative difference: 1.\n x: array([3.141603e-01, 6.283195e-01, 9.424788e-01, 1.256638e+00,\n       6.283185e-12])\n y: array([3.141593e-01, 6.283185e-01, 9.424778e-01, 1.256637e+00,\n       3.141593e-12])"
     ]
    }
   ],
   "source": [
    "from numpy import array, pi\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "expected = array([0.1, 0.2, 0.3, 0.4, 1e-12]) * pi\n",
    "actual = array([0.1, 0.2, 0.3, 0.4, 2e-12]) * pi\n",
    "actual[:-1] += 1e-6\n",
    "assert_allclose(actual, expected, rtol=1e-5, atol=1e-13)  ## elementwise comparison within tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It compares the difference between `actual` and `expected` to ``atol + rtol * abs(expected)``."
   ]
  }
 ],
 "metadata": {
  "jekyll": {
   "display_name": "Test Frameworks"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
